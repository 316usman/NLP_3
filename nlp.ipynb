{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pdfminer.high_level import extract_text\n",
    "\n",
    "def extract_text_from_pdfs(root_folder):\n",
    "    # Iterate over all subdirectories in the root folder\n",
    "    for subdir, dirs, files in os.walk(root_folder):\n",
    "        pdf_files = [f for f in files if f.endswith('.pdf')]\n",
    "        \n",
    "        # Iterate over all PDF files in the subdirectory\n",
    "        for i, pdf_file in enumerate(pdf_files, start=1):\n",
    "            pdf_path = os.path.join(subdir, pdf_file)\n",
    "            \n",
    "            # Extract text from the PDF file\n",
    "            text = extract_text(pdf_path)\n",
    "            \n",
    "            # Save the text to a new .txt file in the same subdirectory\n",
    "            txt_file = os.path.join(subdir, f'{i}.txt')\n",
    "            with open(txt_file, 'w') as f:\n",
    "                f.write(text)\n",
    "\n",
    "# Call the function with the path to your root folder\n",
    "extract_text_from_pdfs('C:\\\\Users\\\\Dell\\\\Desktop\\\\NLP Assignment 3\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from pdfminer.high_level import extract_text\n",
    "vectorizer = CountVectorizer(input='filename')\n",
    "\n",
    "def create_document_term_matrix_with_labels(root_folder):\n",
    "        \n",
    "    # Collect all .txt files in all subdirectories\n",
    "    txt_files = []\n",
    "    labels = []\n",
    "    for subdir, dirs, files in os.walk(root_folder):\n",
    "        for f in files:\n",
    "            \n",
    "            if f.endswith('.txt'):\n",
    "                txt_files.append(os.path.join(subdir, f))\n",
    "                labels.append(os.path.basename(subdir))  # Use the subfolder name as the label\n",
    "    \n",
    "    # Create a document-term matrix\n",
    "    dtm = vectorizer.fit_transform(txt_files)\n",
    "    \n",
    "    # Convert the matrix to a pandas DataFrame\n",
    "    df = pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names_out(), index=['Doc'+str(i+1) for i in range(dtm.shape[0])])\n",
    "    \n",
    "    # Add the labels to the DataFrame\n",
    "    df['label'] = labels\n",
    "    \n",
    "    return df\n",
    "df = create_document_term_matrix_with_labels('C:\\\\Users\\\\Dell\\\\Desktop\\\\NLP Assignment 3\\\\')\n",
    "df_log = np.log1p(df.drop('label', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 27983)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_log.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['00', '000', '0000', '0000446779', '00006', '0001', '00010', '00011',\n",
      "       '00013', '00018',\n",
      "       ...\n",
      "       'ùúáùë¶', 'ùúáùúå', 'ùúå2', 'ùúåth', 'ùúåtotal', 'ùúé2', 'ùúéùúÉ', 'ùúì2', 'ùúìl', 'ùúìùëô'],\n",
      "      dtype='object', length=27983)\n"
     ]
    }
   ],
   "source": [
    "print(df_log.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Doc1     Asp\n",
       "Doc2     Asp\n",
       "Doc3     Asp\n",
       "Doc4     Asp\n",
       "Doc5     Asp\n",
       "Doc6     Asp\n",
       "Doc7     Asp\n",
       "Doc8     Asp\n",
       "Doc9     Asp\n",
       "Doc10    Asp\n",
       "Doc11     DL\n",
       "Doc12     DL\n",
       "Doc13     DL\n",
       "Doc14     DL\n",
       "Doc15     DL\n",
       "Doc16     DL\n",
       "Doc17     DL\n",
       "Doc18     DL\n",
       "Doc19     DL\n",
       "Doc20     DL\n",
       "Doc21    Med\n",
       "Doc22    Med\n",
       "Doc23    Med\n",
       "Doc24    Med\n",
       "Doc25    Med\n",
       "Doc26    Med\n",
       "Doc27    Med\n",
       "Doc28    Med\n",
       "Doc29    Med\n",
       "Doc30    Med\n",
       "Doc31     ML\n",
       "Doc32     ML\n",
       "Doc33     ML\n",
       "Doc34     ML\n",
       "Doc35     ML\n",
       "Doc36     ML\n",
       "Doc37     ML\n",
       "Doc38     ML\n",
       "Doc39     ML\n",
       "Doc40     ML\n",
       "Doc41    NLP\n",
       "Doc42    NLP\n",
       "Doc43    NLP\n",
       "Doc44    NLP\n",
       "Doc45    NLP\n",
       "Doc46    NLP\n",
       "Doc47    NLP\n",
       "Doc48    NLP\n",
       "Doc49    NLP\n",
       "Doc50    NLP\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_txt_converter(doc_path):\n",
    "    text = extract_text(doc_path)\n",
    "    txt_path = os.path.splitext(doc_path)[0] + '.txt'\n",
    "    # Save the text to a new .txt file in the same subdirectory\n",
    "    with open(txt_path, 'w') as f:\n",
    "        f.write(text)\n",
    "    return None\n",
    "\n",
    "def compute_cosine_similarity(new_doc):\n",
    "    if new_doc.endswith('.pdf'):\n",
    "        pdf_to_txt_converter(new_doc)\n",
    "        new_doc = os.path.splitext(new_doc)[0] + '.txt'\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    new_doc_vector = vectorizer.transform([new_doc])\n",
    "    new_doc_row = pd.Series(new_doc_vector.toarray().flatten(), index=vectorizer.get_feature_names_out())\n",
    "    new_doc_list = new_doc_row.drop('label').tolist()\n",
    "    new_doc_list = np.log1p(new_doc_list)\n",
    "    similarities = []\n",
    "    for i in range(df_log.shape[0]):\n",
    "        row = df_log.loc['Doc'+str(i+1)].tolist()\n",
    "        sim = cosine_similarity(np.array(new_doc_list).reshape(1, -1), np.array(row).reshape(1, -1))\n",
    "        similarities.append(sim[0][0])\n",
    "    return similarities\n",
    "#pdf_to_txt_converter('C:\\\\Users\\\\Dell\\\\Desktop\\\\NLP Assignment 3\\\\2312.16724.pdf')\n",
    "x = compute_cosine_similarity(('C:\\\\Users\\\\Dell\\\\Desktop\\\\NLP Assignment 3\\\\2312.16724.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DL\n"
     ]
    }
   ],
   "source": [
    "sublists = [x[i:i+10] for i in range(0, len(x), 10)]\n",
    "averages = [np.mean(sublist) for sublist in sublists]\n",
    "labels = ['Asp','DL', 'Med', 'ML', 'NLP']\n",
    "label = labels[np.argmax(averages)]\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
